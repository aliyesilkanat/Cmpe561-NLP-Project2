{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['\\x99']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['X']\n",
      "['\\xad']\n",
      "['\\x84']\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "insignificant_tokens=[' ','!', '\"','#','$','%','&','*','+','-','(',')',',','.','/','0','1','2','3','4','5','6','7','8',\n",
    "                      '9',';','<','>','=','?','@','|','«','»','`','[',']',\"'\",'\\\\']\n",
    "language_ids=['bg','bs','cz','es-AR','es-ES','hr','id','mk','my','pt-BR','pt-PT','sk','sr']\n",
    "class Result:\n",
    "    expected=\"\"\n",
    "    actual=\"\"\n",
    "class Language: #for each language in data set, we create a Language class\n",
    "   \n",
    "    def __init__ (self,lang_id):\n",
    "        self.chars={} # storing characters and their counts\n",
    "        self.prob={} #storing p(c|l) probability for each character\n",
    "        # corresponding language id \n",
    "        self.lang_id=lang_id\n",
    "    def calculate_probability(self,sentence):\n",
    "        s=list(sentence)\n",
    "        s=[x for x in s if x not in insignificant_tokens]\n",
    "        total=0\n",
    "        for ch in s:\n",
    "            if self.chars.has_key(ch):\n",
    "                total+=self.prob[ch]\n",
    "            else: \n",
    "                return 0\n",
    "        return total\n",
    "    def get_chars(self):\n",
    "        return self.chars\n",
    "    def get_prob(self):\n",
    "        return self.prob\n",
    "    def get_lang_id(self):\n",
    "        return self.lang_id\n",
    "with open (\"Corpus/Raw Corpus.txt\") as f:\n",
    "    corpus = f.readlines()\n",
    "#print(len(corpus))\n",
    "#idx=corpus[0].rfind(\"\\t\")\n",
    "#print (corpus[0][0:idx])\n",
    "#print (corpus[0][idx+1:len(corpus[0])\n",
    "\n",
    "languages=[]\n",
    "model=[]\n",
    "for i in range(13): #divides data set as languages\n",
    "    languages.append(\"\")\n",
    "    start=i*2000\n",
    "    end=(i+1)*2000\n",
    "    languages[i]=corpus[start:end] #2k sentence for each language\n",
    "\n",
    "training_set=[]\n",
    "test_set=[]\n",
    "for idx,l in enumerate(languages):\n",
    "    lang=Language(language_ids[idx])\n",
    "    random.shuffle(l)\n",
    "    \n",
    "    \n",
    "    training_partition=l[0:1800]\n",
    "    training_set.extend(training_partition)\n",
    " \n",
    "    training_partition=[i.split('\\t')[0] for i in training_partition] #remove language identifier at the last of the sentences\n",
    "    for sentence in training_partition:\n",
    "        for letter in sentence:\n",
    "            if letter not in insignificant_tokens:\n",
    "                if lang.get_chars().has_key(letter):\n",
    "                    nominator=lang.get_chars()[letter]\n",
    "                else:\n",
    "                    nominator=0\n",
    "                nominator+=1\n",
    "                lang.get_chars()[letter]=nominator\n",
    "                \n",
    "    test_partition=l[1800:2000]\n",
    "    test_set.extend(test_partition)\n",
    "    test_part=[i.split('\\t')[0] for i in test_partition] #remove language identifier at the last of the sentences\n",
    "    \n",
    "    unk=list(''.join(set(''.join(test_part))))\n",
    "    unk=[x for x in unk if x not in insignificant_tokens]\n",
    "    unk=[x for x in unk if x not in lang.get_chars().keys()]\n",
    "    print(unk)\n",
    "    if len(unk)!=0: # add unknowns characters in test set for smoothing\n",
    "        for l in unk:\n",
    "            lang.get_chars()[l]=0\n",
    "        \n",
    "    for ch in lang.chars: #laplace smoothing\n",
    "        lang.get_chars()[ch]+=1\n",
    "    \n",
    "    denominator=sum(lang.get_chars().values())+len(lang.get_chars().values()) #for performance\n",
    "    for letter in lang.get_chars(): #calculate probabilities\n",
    "        lang.get_prob()[letter]=(lang.get_chars()[letter]+1)/float(denominator)\n",
    "  \n",
    "\n",
    "    model.append(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238\n",
      "2600\n",
      "47.6153846154\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for sentence in test_set:\n",
    "    s=sentence.split('\\t')\n",
    "    probabilities={}\n",
    "    \n",
    "    for l_model in model:\n",
    "        probabilities[l_model.get_lang_id()]=l_model.calculate_probability(s[0])\n",
    "    if s[1].strip()==max(probabilities.items(), key=lambda k: k[1])[0]:\n",
    "        i+=1\n",
    "    \n",
    "print (i)\n",
    "print (len(test_set))\n",
    "print((100.0*i)/float(len(test_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_files(file_name,array):\n",
    "    with open (file_name, mode='wt') as t_file:\n",
    "        for item in array:\n",
    "            t_file.write(item)\n",
    "print(len(training_set))\n",
    "print(len(test_set))\n",
    "write_files(\"Training set.txt\",training_set)\n",
    "write_files(\"Test set.txt\",test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
